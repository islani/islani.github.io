<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Resume</title>
    <link rel="icon" href="img/favicon.ico" type="image/x-icon">
    <!-- Bootstrap -->
    <link href="css/bootstrap.min.css" rel="stylesheet">
    <link href="ionicons/css/ionicons.min.css" rel="stylesheet">
    <link href="css/animate.min.css" rel="stylesheet">
    <link href="css/aos.css" rel="stylesheet">
    <!-- main style -->
    <link href="css/style.css" rel="stylesheet">
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
</head>

<body>

    <!-- Preloader -->
    <div id="preloader">
        <div id="status">

            <div class="preloader" aria-busy="true" aria-label="Loading, please wait." role="progressbar">
            </div>

        </div>
    </div>
    <!-- ./Preloader -->
    
    <!-- header -->
    <header class="navbar-fixed-top">
        <nav>
            <ul>
                <li><a href="#about">About</a></li>
                <li><a href="#experience">experience</a></li>
                <li><a href="#research">research</a></li>
                <li><a href="#teaching">teaching</a></li>
                <li><a href="#art">art</a></li>
                <li><a href="#education">education</a></li>
                
            </ul>
        </nav>
    </header>
    <!-- ./header -->
    
    <!-- home -->
    <div class="section" id="home" data-stellar-background-ratio="0.5">
        <div class="container">
            <div class="disply-table">
                <div class="table-cell" data-aos="fade-up" data-aos-delay="0">
                    <h4>Dr. Ilhan Aslan</h4>
                    <h1>Researcher <br />& Artist</h1> </div> 
            </div>
        </div>
    </div>
    <!-- ./home -->
    
    <!-- about -->
    <div class="section" id="about">
        <div class="container">
            <div class="col-md-6" data-aos="fade-up">
                <h4>01</h4>
                <h1 class="size-50">About me</h1>
                <div class="h-50"></div>
                <p> I am a German researcher and artist born in Turkey. I have studied Computer Science in Saarbrücken, Germany, and received a PhD end of 2014 from Salzburg University in Austria, conducting research at the interdiciplinary Center for HCI. 
                    My research is often transdiciplinary and continues to revolve around two main areas: (i) improving HCI through the study and application of emerging technologies
                    and (ii) (emotional) AI development for human-centered design.
                    I consider my computing and design research as positive and constructive (and occasionally critical), aiming to test the current state of human-artefact relations in specific situations and to explore future (digital) alternatives.
                    
                </p>
                <div class="h-50"></div> <img src="img/Signature.jpg" width="70px" alt="" />
                 
            </div>
            
            <div class="col-md-6 about-img-div">
                <img src="img/about-img.jpg" width="400" class="img-responsive" alt="" align="right" data-aos="fade-right" data-aos-delay="0" />
            </div>

                
        </div>
        
    </div>
    <!-- ./about -->
   
   


    <!-- experience  -->
    <div class="section" id="experience">
        <div class="container">
            <div class="col-md-12">
                <h4>02</h4>
                <h1 class="size-50">Experience</h1>
                <div class="h-50"></div>
            </div>
            <div class="col-md-12">
                <ul class="timeline">
                    <li class="timeline-event" data-aos="fade-up">
                        <label class="timeline-event-icon"></label>
                        <div class="timeline-event-copy">
                            <p class="timeline-event-thumbnail"> Sempter 2024 - </p>
                            <h3>Aalborg University, Denmark</h3> <br />
                            <strong>Associate Professor</strong>
                            <br />
                            @ Human-Centered Computing Group, Department of Computer Science
                            <br />
                            
                            <br /><br />
                           
                        </div>
                    </li>
                    <li class="timeline-event" data-aos="fade-up">
                        <label class="timeline-event-icon"></label>
                        <div class="timeline-event-copy">
                            <p class="timeline-event-thumbnail">January 2020 - May 2024</p>
                            <h3>Huawei Technologies, Germany</h3> <br />
                            <strong>Senior HCI Research Scientist, Lead HCI Research Team</strong>
                            <br />
                            @ Device Software Lab, Munich Research Center, Consumer Business Group
                            <br />
                            Research Focus: Improving HCI with Affective Computing (Machine Learning for emotional HCI), Consumer Device Use Cases
                            <br /><br />
                           
                        </div>
                    </li>
                    <li class="timeline-event" data-aos="fade-up" data-aos-delay=".2">
                        <label class="timeline-event-icon"></label>
                        <div class="timeline-event-copy">
                            <p class="timeline-event-thumbnail">July 2015 - December 2020</p>
                            <h3>Augsburg University, Germany </h3> 
                            <strong>Postdoc/Akademischer Rat a.Z. (~ Assistant Professor) </strong>
                            <br />
                            @ Human-Centered AI Lab, Department of Computer Science,
                            <br />
                            Research Focus: Improving HCI with Multimodal Interaction Design and Positive/Affective Computing, HRI and Mental Health Use Cases  
                            <br /><br />
                           
                        </div>
                    </li>
                    <li class="timeline-event" data-aos="fade-up" data-aos-delay=".4">
                        <label class="timeline-event-icon"></label>
                        <div class="timeline-event-copy">
                            <p class="timeline-event-thumbnail"> September 2010 - June 2015</p>
                            <h3>Salzburg University,  Austria </h3> 
                            <strong>Researcher, Postdoc, Project Lead, Co-Lead "Embodied Interaction Design" team  </strong>
                            <br />
                            @ Embodied Interaction Design Team, Center for HCI
                            <br />
                            Research Focus: Improving HCI with Human-Centered Interaction Design and Contextual Interfaces; Smart Home, Factory, and Automotive Use Cases
                            <br /><br />
                            
                        </div>
                    </li>
                    <li class="timeline-event" data-aos="fade-up" data-aos-delay=".6">
                        <label class="timeline-event-icon"></label>
                        <div class="timeline-event-copy">
                            <p class="timeline-event-thumbnail"> March 2007 - August 2010</p>
                            <h3>Fraunhofer ESK, Munich, Germany  </h3>
                            <strong>Researcher, Interaction Designer & Project Lead </strong>
                            <br />
                            @ Mobile Applications Group, Enterprise Communication
                            <br />
                            Research Focus: Improving Mobile HCI with Multimodal Interaction Design and Contextual Interfaces, SME Use Cases
                            <br /><br />
                            
                        </div>
                    </li>
                    <li class="timeline-event" data-aos="fade-up" data-aos-delay=".8">
                        <label class="timeline-event-icon"></label>
                        <div class="timeline-event-copy">
                            <p class="timeline-event-thumbnail"> October 2004 - February 2007</p>
                            <h3>DFKI (German Research Center for AI), Saarbrücken, Germany</h3> 
                            <strong>Researcher, Interaction Designer</strong>
                            <br />
                            @ Intelligent User Interfaces Department
                            <br />
                            Research Focus: Improving Mobile HCI with Multimodal & Multilingual Interaction Design and Contextual Interfaces, Travel/Touristic Assistance Use Cases
                            <br /><br />
                            
                        </div>
                    </li>
                    <li class="timeline-event" data-aos="fade-up" data-aos-delay="1.">
                        <label class="timeline-event-icon"></label>
                        <div class="timeline-event-copy">
                            <p class="timeline-event-thumbnail"> 1998 - Oktober 2004</p>
                            <h3>Part-time jobs</h3> 
                            <strong>Perl/C/VC++ Programmer, Tutor/TA for CS Lectures, AI-lab Research Asssistant </strong>
                            <br />
                            @ Saarland University & DFKI spin-offs, Germany
                            <br /><br />
                            
                            
                        </div>
                    </li>
                    
                 </ul>
               
            </div>
        </div>
    </div>
    <!-- ./experience -->
    


<!-- ./research -->


<div class="section" id="research">
    <div class="container">
        <div class="col-md-12">
            <h4>03</h4>
            <h1 class="size-50">Research</h1> 
        </div>
 <!-- ilhan -->
    <div class="container">
        <div class="portfolio-padding">
            <img src="img/portfolio/r1.jpg" alt="" class="img-responsive" />
                
            <div class="col-md-8 col-md-offset-2"> 
       
                
                <br />
                <br />

                My early research was greatly influenced by visionaries such as Mark Weiser and his concept of
                Ubiquitous Computing, as well as Paul Dourish's insightful book "Where the Action Is: The
                Foundation of Embodied Interaction," and Löwgren and Stolterman's "Thoughtful Interaction
                Design: A Design Perspective on Information Technology."
                As my interests evolved, I turned my attention to designing multimodal interactions for the well-
                being of individuals and enhancing human potential. Calvo and Peter's work on "Positive
                Computing" served as a significant source of inspiration during this phase.To better comprehend the
                profound connection between our bodies and our experiences in relation to the environment, I
                began drawing inspiration from diverse disciplines and fields. Notably, Shusterman's philosophical
                work on Somaesthetics and Hartmud Rosa's social work on "Resonance Theory" provided valuable
                insights that shaped my human-centered approach to designing emerging technologies.
                <br /><br />

                
                My main research is about improving HCI through the study and application of emerging technologies,
                and one class of important emerging technologies has been machine learning solutions. ML is enabling a new wave of human-centered user interface and experience designs. To this end, I have been studying the realm of highly perceptive, interactive, and emotional AI
                development.
                <h2>"Recent" research publication highlights</h2> 
                Recent publications worth mentioning are the IUI 2022 paper titled <strong>"Robust and Deployable Gesture Recognition for Smartwatches"</strong> 
                which was a result of a collaboration with Aalto University, where I have been the co-advisor of 
                Utkarsh Kunwar's graduate research (<a href="papers/robust_gesture.pdf" target="_blank" title="Read PDF">open pdf</a>). The resulting paper is a good example
                of research combining human centered design methods with state of the art AI techniques to create "usable/useful" smart technology.  
                An extended version of our paper titled <strong>"How to Compliment a Human - Designing Affective and
                Well-being Promoting Conversational Things"</strong> has been accepted and apeared early 2024 in the journal for IxD & Architecture(s). The extended journal version is available here: (<a href="papers/cui.pdf" target="_blank" title="Read PDF">open pdf</a>) or at the journal´s website <a href="https://ixdea.org/table-of-contents-n-58/" target="_blank" title="Read PDF">https://ixdea.org/table-of-contents-n-58/</a>). 
                The paper describes iterative human centered design research (including a month long exhibition in an architecture museum) to enable artifacts to generate meaningful and positive utterances (i.e. compliments) using machine learning based visual perception (Computer Vision). We also touch the topic of large language models and human-centered prompt engineering. 
                And most recently (spring, 2024) our submission  titled <strong>"Audio Enhancement for Computer Audition – An Iterative Training Paradigm Using Sample Importance" </strong> to the international Journal of Computer Science and Technology has been accepted. The paper describes a novel ML training technique to achieve robustness in various (mostly HCI related) computer audition applications (e.g., emotion recognition, automatic speech recognition, audio scene analysis) which we evaluated in multiple experiments.
                Here you can access the accepted preprint version of the submission (<a href="papers/AE_CA_preprint.pdf" target="_blank" title="Read PDF">open pdf</a>)  
                
                <br /><br />

                <table class="table table-responsive">
                    <tr>
                        <td><img src="media/watch_tn.png" alt="image" width="200px" /></td>
                        <td><ul><li>Kunwar, U., Borar, S., Berghofer, M., Kylmälä, J., Aslan, I., Leiva, A., & Oulasvirta, A. (2022). Robust and deployable gesture recognition for smartwatches. In Proceedings of 27th International Conference on Intelligent User Interfaces (pp. 277-291).<a href="papers/robust_gesture.pdf" target="_blank" title="Read PDF">open pdf</a></li></ul></td>
                 
                    </tr>
                   
                    <tr>
                        <td><img src="media/mirror_tn.png" alt="image" width="200px" /></td>
                        <td><ul><li>Aslan, I., Neu, D., Neupert, D., Grafberger, S., Weise, N., Pfeil, P., & Kuschewski, M. (2023). How to Compliment a Human – Designing Affective and Well-being Promoting Conversational Things. Interaction Design & Architecture(s) Journal (pp. 157-184). (https://doi.org/10.55612/s-5002-058-007) <a href="papers/cui.pdf" target="_blank" title="Read PDF">open pdf</a></li></ul></td>
                   
                      </tr>

                    <tr>
                        <td><img src="media/ASR_tn.png" alt="image" width="200px" /></td>
                        <td><ul><li>Milling, M., Liu, S., Triantafyllopoulos, A., Aslan, I., & Schuller, B. (2024). Audio Enhancement for Computer Audition – An Iterative Training Paradigm Using Sample Importance. In Journal of Computer Science and Technology.<a href="papers/AE_CA_preprint.pdf" target="_blank" title="Read PDF"> open pdf (preprint version)</a></li></ul></td>
                 
                    </tr>
                   
                  </table> 
                <hr />

                <h2>Award winning research</h2>  
                The following research papers have been nominated for best paper runner-up. 
                Two papers are about gestures (participative design of gestures, and a proof of concept for using mid-air gestures as a form of "biometric-behavioral" authentication), 
                and the other two are about using AI (interactive ML, and RL) for user behavior adaptive interactions (i.e., personalization of drink activity recognizers on a smartwatch, and adapting the behavior of robots)  
                <br /><br />


                <table class="table table-responsive">
                    <tr>
                      <td><img src="media/humour_tn.png" alt="image" width="200px" /></td>
                      <td><ul><li>Weber, K., Ritschel, H., Aslan, I., Lingenfelser, F., & André, E. (2018, October). How to shape the humor of a robot-social behavior adaptation based on reinforcement learning. In Proceedings of the 20th ACM international conference on multimodal interaction (pp. 154-162).<a href="papers/humor.pdf" target="_blank" title="Read PDF"> open pdf</a></li></ul></td>
                 
                    </tr>
                   
                    <tr>
                        <td><img src="media/gesture_tn.png" alt="image" width="200px" /></td>
                        <td><ul><li>Aslan, I., Schmidt, T., Woehrle, J., Vogel, L., & André, E. (2018, October). Pen+ mid-air gestures: Eliciting contextual gestures. In Proceedings of the 20th ACM International Conference on Multimodal Interaction (pp. 135-144).<a href="papers/gesturedesign.pdf" target="_blank" title="Read PDF"> open pdf</a></li></ul></td>
                 
                    </tr>
                    
                    <tr>
                        <td><img src="media/drinkwatch_tn.png" alt="image" width="200px" /></td>
                        <td><ul><li>Flutura, S., Seiderer, A., Aslan, I., Dang, C. T., Schwarz, R., Schiller, D., & André, E. (2018, April). Drinkwatch: A mobile wellbeing application based on interactive and cooperative machine learning. In Proceedings of the 2018 International Conference on Digital Health (pp. 65-74).<a href="papers/drinkwatch.pdf" target="_blank" title="Read PDF"> open pdf</a></li></ul></td>
                 
                    </tr>
                   
                    <tr>
                        <td><img src="media/authentication_tn.png" alt="image" width="200px" /></td>
                        <td><ul><li>Aslan, I., Uhl, A., Meschtscherjakov, A., & Tscheligi, M. (2014, November). Mid-air authentication gestures: An exploration of authentication based on palm and finger motions. In Proceedings of the 16th International Conference on Multimodal Interaction (pp. 311-318).<a href="papers/authentication.pdf" target="_blank" title="Read PDF"> open pdf</a></li></ul></td>
                 
                    </tr>
                  </table> 
                <hr />

                <h2>Joint Lab on Affective Computing </h2>
                Affective Computing is simply put an extension of the field of HCI, making mainly use of (human-centered) Machine Learning
                solutions to enable machines to recognize, express/mimic, or stimulate affective user contexts (e.g., emotional states).  
                From beginning of 2020 until mid 2023 I managed the Affective Computing and HCI Joint Innvovation Lab and all sub projects between Augsburg University and 
                Huawei, in the process co-advicing the research work of all the PhDs within the joint-lab projects:
                <ul>
                    <li> "Smart Tutor" project, including research on recognizing and adapting to affective learner states, such as engagement and frustration (PhD researchers from Augsburg University: Alina Leidinger, Michael Dietz, Fabio Hellman, Anan Schütt)</li>
                    <li> "Emotional TTS" project,  including research in Voice Conversion, Speech Emotion Recognition, and Text Emotion Recognition (PhD researchers from Augsburg University: Lukas Christ, Thobias Hübner, Zijiang Yang, Meishu Song, Shuo Liu)</li>
                    <li> "Audio Enhancement" project,  mainly to enable robust Automatic Speech Recognition (PhD researchers from Augsburg University: Shuo Liu)</li>
                    <li> "Affective Multimodal Dataset" project, including reserach in Tool-support for semi-autonomously collecting and labelling Datasets (PhD researchers from Augsburg University: Meishu Song) </li>

                </ul>   
                While managing the Machine Learning projects I had to follow the white AI rabbit, extending my expertise in 
                ML and AI trough the regular discourses with all the ML PhDs working on the projects.
                I am thankful for everyone I worked with, including internal colleagues from Huawei who were located all around the world.    


                <h2>Academic Research Examples with Demo Videos</h2>
                For the following (public) case studies the available video material provide deeper insights to my research activities, especially my human-centered and multimodal interaction design activites and the mixed-methodologies
                that I typically use.   
                
                <h3>Tangible Heart Displays</h3>    

                <table class="table table-responsive">
                    <tr>
                      <td><img src="media/pihearts_tn.png" alt="image" width="200px" /></td>
                      <td><ul><li>Aslan, I., Seiderer, A., Dang, C. T., Rädler, S., & André, E. (2020, October). PiHearts: Resonating Experiences of Self and Others Enabled by a Tangible Somaesthetic Design. In Proceedings of the 2020 International Conference on Multimodal Interaction (pp. 433-441).<a href="papers/tangibleheart.pdf" target="_blank" title="Read PDF"> open pdf</a></li></ul></td>
                    </tr>
                </table> 
 
                The paper was presented at ICMI 2020, which was due to Covid an online only event. 
                The positive is that there is short recording of my 8min presentation of the paper on youtube in which I also touch 
                on the theories which motivates the research and design decisions. 
                <br />
                <br />  
                <iframe width="100%" height="400" src="https://www.youtube.com/embed/ebL-EpYDh0Y">
                </iframe> 
                <br />
                <br />
                <br />

                <h3>Human-Robot Interaction</h3>
                <table class="table table-responsive">
                    <tr>
                      <td><img src="media/irony_tn.png" alt="image" width="200px" /></td>
                      <td><ul><li>Ritschel, H., Aslan, I., Sedlbauer, D., & André, E. Irony Man: Augmenting a Social Robot with the Ability to Use Irony in Multimodal Communication with Humans. Proc. of the 18th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2019).<a href="papers/ironyman.pdf" target="_blank" title="Read PDF"> open pdf</a></li></ul></td>
                    </tr>
                </table> 

                <iframe width="100%" height="400" src="https://www.youtube.com/embed/ZeN37TDuUCE">
                </iframe> 
                <br />
                <br />
               
           
                <h3>Pre-touch Proxemics</h3> 
                <table class="table table-responsive">
                    <tr>
                      <td><img src="media/pretouch_tn.png" alt="image" width="200px" /></td>
                      <td><ul><li>Aslan, I., & André, E. (2017, November). Pre-touch proxemics: Moving the design space of touch targets from still graphics towards proxemic behaviors. In Proceedings of the 19th ACM International Conference on Multimodal Interaction (pp. 101-109).<a href="papers/pre_touch_proxemics.pdf" target="_blank" title="Read PDF"> open pdf</a></li></ul></td>
                    </tr>
                </table> 
                <video width="100%" height="450px" controls>
                    <source src="media/pre_touch.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                  </video>
                  <br />
             
                  <table class="table table-responsive">
                    <tr>
                        <td><img src="media/car_tn.png" alt="image" width="200px" /></td>
                        <td><ul><li>Aslan, I., Krischkowsky, A., Meschtscherjakov, A., Wuchse, M., & Tscheligi, M. (2015, September). A leap for touch: proximity sensitive touch targets in cars. In Proceedings of the 7th International Conference on Automotive User Interfaces and Interactive Vehicular Applications (pp. 39-46).<a href="papers/car.pdf" target="_blank" title="Read PDF"> open pdf</a></li></ul></td>
                      </tr>
                 </table> 
                 
                 <video width="100%" height="450px" controls>
                    <source src="media/car.mov" type="video/mp4">
                    Your browser does not support the video tag.
                  </video>

                  <table class="table table-responsive">
                    <tr>
                        <td><img src="media/leaparm_tn.png" alt="image" width="200px" /></td>
                        <td><ul><li>Aslan, I., Kraus, J., & André, E. (2016, October). LeapArm-facilitating sensory spaces for mid-air gestural interaction. In Proceedings of the 9th Nordic Conference on Human-Computer Interaction (pp. 1-6).<a href="papers/car.pdf" target="_blank" title="Read PDF"> open pdf</a></li></ul></td>
                      </tr>
                 </table> 
          
                 <video width="100%" height="450px" controls>
                    <source src="media/leaparm.mov" type="video/mp4">
                    Your browser does not support the video tag.
                  </video>

                  
                  <h3>IoT plants and implicit interaction design</h3> 
                  <table class="table table-responsive">
                    <tr>
                      <td><img src="media/iot_plants.png" alt="image" width="200px" /></td>
                      <td><ul><li>Bittner, B., Aslan, I., Dang, C. T., & André, E. (2019, March). Of Smarthomes, IoT Plants, and Implicit Interaction Design. In Proceedings of the Thirteenth International Conference on Tangible, Embedded, and Embodied Interaction (pp. 145-154).<a href="papers/iot_plants_design.pdf" target="_blank" title="Read PDF"> open pdf</a></li></ul></td>
                    </tr>
                  </table>
                  <video width="100%" height="450px" controls>
                    <source src="media/plants.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                  </video> 
                  <br />
                  <br />

                  <h3>Digital Bookshelf</h3> 
                  <table class="table table-responsive">
                    <tr>
                      <td><img src="media/digitalbookshelf_tn.png" alt="image" width="200px" /></td>
                      <td><ul><li>Moser, C., Aslan, I., Neureiter, K., Randelshofer, I., Sundstroem, P., & Tscheligi, M. (2018). Exploring intended and unintended uses of (e) books as design inspiration for ambient displays in the home.<a href="papers/digital_bookshelf.pdf" target="_blank" title="Read PDF"> open pdf</a></li></ul></td>
                    </tr>
                  </table>
                  <video width="100%" height="450px" controls>
                    <source src="media/bookshelf.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                  </video> 
                  <br />
                  <br />
                  
                  <h3>Gaze interaction in Games</h3> 
                  <table class="table table-responsive">
                    <tr>
                      <td><img src="media/gaze_tn.png" alt="image" width="200px" /></td>
                      <td><ul><li> Maurer, B., Aslan, I., Wuchse, M., Neureiter, K., & Tscheligi, M. (2015, October). Gaze-based onlooker integration: exploring the in-between of active player and passive spectator in co-located gaming. In Proceedings of the 2015 Annual Symposium on Computer-Human Interaction in Play (pp. 163-173).
                        <a href="https://dl.acm.org/doi/abs/10.1145/2793107.2793126" target="_blank" title="Read PDF"> open pdf</a></li></ul></td>
                    </tr>
                  </table>
                  <video width="100%" height="450px" controls>
                    <source src="media/gaze.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                  </video> 
                  <br />
                  <br />

                 
                

                <div class="h-50"></div>
                
                <br />
              
                <p>
                <!--     
                <a id="demo04" href="#animatedModal" class="portfolio_item"> <img src="img/portfolio/01.jpg" alt="image" width="300px"/>
                </a>
                -->

            </div>
        </div>
    </div>
</div>
<!-- ilhan -->

<!-- experience  -->
<div class="section" id="teaching">
    
    <div class="container">
        <div class="col-md-12">
            <h4>04</h4>
            <h1 class="size-50">Teaching</h1> 
            <div class="h-50"></div>
        </div>
        <div class="col-md-8 col-md-offset-2">
        I was a lecturer both at
        Augsburg University in Germany and Salzburg University in Austria.
        Before, I have taken lead TA and TA roles in Saarbrücken, at Saarland University.
        I was an advisor and mentor for multiple graduate students at Universties.
        I have also taken the role of co-advicer and co-mentor from industry during my time at Fraunhofer and Huawei when students 
        have worked on their theses and internships with me. For example, at Huawei I have co-supervised the master theses of 
      
        <ul>
            <li>Utkarsh Kunwar (which resulted in a IUI full paper in 2022
            <a href="papers/robust_gesture.pdf" target="_blank" title="Read PDF"> open pdf</a>)</li>
        </ul>
        <ul>
            <li>Moritz Berghofer (which resulted in a separate paper at the 7th International Workshop on Sensor-based Activity Recognition and Artificial Intelligence in 2022
                <a href="https://dl.acm.org/doi/abs/10.1145/3558884.3558896" target="_blank" title="Read PDF at ACM"> open ACM link</a>)</li>
        
                
            </li>
             <li>Muhammad Mehran Sunny (which resulted in a CHI 2011 workshop presentation/paper <a href="https://dl.acm.org/doi/abs/10.1145/3411763.3441325" target="_blank" title="Read PDF at ACM"> open ACM link</a>) </li>
        
        </ul>

        
        In the past I have mainly taught HCI and IxD lectures but I am also able to teach AI and ML lectures, including introductory but also advanced lectures about generative ML, Affective Compuitng, Intelligent UIs, AI for embedded/wearable devices, Multimodal ML,  ML for NLP and conversational UIs.
        I am also comfortable programming and developing functional prototypes in various programming languages.

        <br /><br />

        <h3>Teaching @ Augsburg University, Germany</h3>
        <table>
            <tr>
              <td>Human-Computer Interaction</td>
              <td>SS 2019, SS 2018, SS 2017, 2016</td>
              <td>lecturer</td>
            </tr>
            <tr>
                <td>Multimedia 1</td>
                <td>2018/19, 2017/18, 2016/17</td>
                <td>lecturer</td>
            </tr>
            <tr>
                <td>Praktikum (Studio) Usability Engineering</td>
                <td>2019, 2017, 2016</td>
                <td>lecturer</td>
            </tr>
            <tr>
                <td>Machine Learning and Innovative Interaction Technologies Seminar</td>
                <td>2018/19</td>
                <td>lecturer</td>
            </tr>
            <tr>
                <td>Usability Engineering</td>
                <td>2018/19, 2017/18, 2016/17, 2015/16</td>
                <td>lecturer</td>
            </tr>
            <tr>
                <td>Physical Computing</td>
                <td>2017/18, 2016/17, 2015/16</td>
                <td>lecturer</td>
            </tr>
        </table>


        <h3>Teaching @ Paris-Lodron University Salzburg, Austria</h3>
        <table>
            <tr>
                <td>User Interface Engineering</td>
                <td>2015</td>
                <td>lecturer</td>
            </tr>
            <tr>
                <td> HCI: case studies</td>
                <td>2014</td>
                <td>lecturer</td>
            </tr>
            <tr>
                <td> User Interface Design</td>
                <td>2013/14</td>
                <td>lecturer</td>
            </tr>
        </table>
        <h3>Teaching @ Saarland University, Germany</h3>
        <table>
            <tr>
                <td> Introduction to AI</td>
                <td>2005/06</td>
                <td>Lead TA</td>
            </tr>
            <tr>
                <td>Semantic Web Technologies</td>
                <td>2005</td>
                <td>Lead TA</td>
            </tr>
                    <tr>
                <td> Data Structures and Algorithms</td>
                <td>2000/01, 2001/02</td>
                <td>TA</td>
            </tr>
            <tr>
                <td> Computer Science 3 (Theoretical Computer Science)</td>
                <td>2000/01, 2001/02 </td>
                <td>TA</td>
            </tr>
            <tr>
                <td> Computer Science 2 (Intro to CS, System Architectures)</td>
                <td>1999, 2000 </td>
                <td>TA</td>
            </tr>
        </table>
          
        
    </div>
          
    <div class="h-50"></div>
       
        
    </div>
</div>
<!-- ./teaching -->


        <!-- art -->
        <div class="section" id="art">
            <div class="container">
                <div class="col-md-12">
                    <h4>05</h4>
                    <h1 class="size-50">Art Gallery</h1> 
                    <div class="h-50"></div>
                </div>

                 <!-- ilhan -->
                <div class="container">
                    <div class="portfolio-padding">
                        <div class="col-md-8 col-md-offset-2">
                            
                            <p> 
                                My art compensates my research and design activities focussed on software/code, grounding me often to physical materials and crafting with my eyes, hands, and body.   
                                I enjoy painting for my friends, or painting 
                                self-portraits as a somaesthetic practice of self-reflection and expression. 
                                I enjoy both painting on large and small canvases. On small canvases I prefer to paint portraits. 
                                I enjoy expressing my feelings expreimenting with colors.
                                This art gallery shows a few samples of my paintings.
                            </p>
                    
                            <br />
                            <br />
                            <div class="h-30"></div>
                           
                    </div>
                </div>
            <!-- ilhan -->

                <!-- main container -->
                <div class="main-container portfolio-inner clearfix">
                    <!-- portfolio div -->
                    <div class="portfolio-div">
                        <div class="portfolio">
                            
                            
                            <!-- portfolio_container -->
                            <div class="no-padding portfolio_container clearfix" data-aos="fade-up">
                               
                                
                                <!-- single work -->
                                <div class="col-md-4 col-sm-6">
                                    <div  class="portfolio_item"> <img src="img/portfolio/01.jpg" alt="image" class="img-responsive" />
                                   
                                    </div>
                                </div>
                                <!-- end single work -->
                                
                                <!-- single work -->
                                <div class="col-md-4 col-sm-6 ">
                                    <div  class="portfolio_item">  <img src="img/portfolio/02.jpg" alt="image" class="img-responsive" />
                                      
                                    </div>
                                </div>
                                <!-- end single work -->
                                
                                <!-- single work -->
                                <div class="col-md-4 col-sm-6">
                                    <div  class="portfolio_item">  <img src="img/portfolio/03.jpg" alt="image" class="img-responsive" />
                                      
                                    </div>
                                </div>
                                <!-- end single work -->
                                
                                <!-- single work -->
                                <div class="col-md-4 col-sm-6 ">
                                    <div  class="portfolio_item"> <img src="img/portfolio/04.jpg" alt="image" class="img-responsive" />
                                     
                                    </div>
                                </div>
                                <!-- end single work -->
                                
                                <!-- single work -->
                                <div class="col-md-4 col-sm-6">
                                    <div  class="portfolio_item">  <img src="img/portfolio/05.jpg" alt="image" class="img-responsive" />
                                     
                                    </div>
                                </div>
                                <!-- end single work -->
                                
                                <!-- single work -->
                                <div class="col-md-4 col-sm-6 ">
                                    <div  class="portfolio_item"> <img src="img/portfolio/06.jpg" alt="image" class="img-responsive" />
                                      
                                    </div>
                                </div>
                                <!-- end single work -->
                                <!-- single work -->
                                <div class="col-md-4 col-sm-6">
                                    <div  class="portfolio_item">  <img src="img/portfolio/07.jpg" alt="image" class="img-responsive" />
                                      
                                    </div>
                                </div>
                                <!-- end single work -->
                                 <!-- single work -->
                                 <div class="col-md-4 col-sm-6 ">
                                    <div  class="portfolio_item"> <img src="img/portfolio/08.jpg" alt="image" class="img-responsive" />
                                      
                                    </div>
                                </div>
                                <!-- end single work -->
                                 <!-- single work -->
                                 <div class="col-md-4 col-sm-6 ">
                                    <div  class="portfolio_item">  <img src="img/portfolio/09.jpg" alt="image" class="img-responsive" />
                                      
                                    </div>
                                </div>
                                <!-- end single work -->
                                  <!-- single work -->
                                  <div class="col-md-4 col-sm-6 ">
                                    <div  class="portfolio_item">  <img src="img/portfolio/010.jpg" alt="image" class="img-responsive" />
                                      
                                    </div>
                                </div>
                                <!-- end single work -->
                                  <!-- single work -->
                                  <div class="col-md-4 col-sm-6 ">
                                    <div  class="portfolio_item"> <img src="img/portfolio/011.jpg" alt="image" class="img-responsive" />
                                      
                                    </div>
                                </div>
                                <!-- end single work -->
                                  <!-- single work -->
                                  <div class="col-md-4 col-sm-6 ">
                                    <div  class="portfolio_item">  <img src="img/portfolio/012.jpg" alt="image" class="img-responsive" />
                                      
                                    </div>
                                </div>
                                <!-- end single work -->
                                  <!-- single work -->
                                  <div class="col-md-4 col-sm-6 ">
                                    <div  class="portfolio_item"> <img src="img/portfolio/013.jpg" alt="image" class="img-responsive" />
                                      
                                    </div>
                                </div>
                                <!-- end single work -->
                                  <!-- single work -->
                                  <div class="col-md-4 col-sm-6 ">
                                    <div  class="portfolio_item"> <img src="img/portfolio/014.jpg" alt="image" class="img-responsive" />
                                      
                                    </div>
                                </div>
                                <!-- end single work -->
                                  <!-- single work -->
                                  <div class="col-md-4 col-sm-6 ">
                                    <div  class="portfolio_item">  <img src="img/portfolio/015.jpg" alt="image" class="img-responsive" />
                                      
                                    </div>
                                </div>
                                <!-- end single work -->
                                
                                 
                            </div>
                            <!-- end portfolio_container -->
                        </div>
                        <!-- portfolio -->
                    </div>
                    <!-- end portfolio div -->
                </div>
                <!-- end main container -->
            </div>
        </div>
        <!-- ./art -->
        


 <!-- education -->
 <div class="section" id="education">
    <div class="container">
        <div class="col-md-12">
            <h4>06</h4>
            <h1 class="size-50">Education</h1>
            <div class="h-50"></div>
        </div>
        <div class="col-md-12">
            <ul class="timeline">
                <li class="timeline-event" data-aos="fade-up">
                    <label class="timeline-event-icon"></label>
                    <div class="timeline-event-copy">
                        <p class="timeline-event-thumbnail">End of 2014</p>
                        <h3>PhD (Dr. techn.) </h3> 
                        @ Center for HCI, Paris Lodron University, Salzburg, Austria <br />
                        
                        PhD thesis: <strong>"Interfacing Through Movement: An Integration of Context and
                        Movement-Based Interaction towards Embodied Interaction Design”. </strong><br /> 
                        Thesis grade: “sehr gut (1)”. (Supervisor: Prof. for HCI Dr. Manfred Tscheligi & Postdoc Dr. Alexander Meschtscherjakov)
                    </div>
                </li>
                <li class="timeline-event" data-aos="fade-up" data-aos-delay=".2">
                    <label class="timeline-event-icon"></label>
                    <div class="timeline-event-copy">
                        <p class="timeline-event-thumbnail">End of 2004</p>
                        <h3>Computer Science Diplom (Dipl. Inf.)</h3> 
                        @ AI lab, Universität des Saarlandes, Saarbrücken, Germany <br />
                      
                        Diplom thesis: <strong>"The Bum Bag Navigator: A Configurable Mobile Multi-purpose
                        Navigation System for Pedestrians”.</strong> <br /> 
                        Thesis grade: “sehr gut 1.3” (Supervisor: Prof. for AI Dr. Wolfgang Wahlster & Postdoc Dr. Antonio Krüger) 

                        <br /><br />
                        
                    </div>
                </li>
               
            </ul>
        </div>
    </div>
</div>
<!-- ./education -->

<!-- contact -->
<div class="section" id="contact">
    <div class="container">
        <div class="col-md-12">
            <h4>07</h4>
            <h1 class="size-50">Contact  Me</h1>
            <div class="h-50"></div>
        </div>

        <div class="col-md-4" data-aos="fade-up">

          
            <p>to be defined</p>
           
            <div class="clearfix"></div>
            <div class="h-50"></div>
        </div>
        
    </div>
</div>

<!-- ./contact -->
 

    <!-- jQuery -->
    <script src="js/jquery.js"></script>
    <!--  plugins  -->
    <script src="js/bootstrap.min.js"></script>
    <script src="js/plugins.js"></script>
    <script src="js/aos.js"></script>
    <script src="js/jquery.form.js"></script>
    <script src="js/jquery.validate.min.js"></script>

    <!--  main script  -->
    <script src="js/custom.js"></script>
</body>

</html>